{"ast":null,"code":"/*\n * Copyright (c) 2019 by Filestack.\n * Some rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport * as tslib_1 from \"tslib\";\nimport PQueue from 'p-queue';\nimport Debug from 'debug';\nimport { postWithRetry, request, useRetryPolicy, shouldRetry } from './../../request';\nimport { uniqueTime, uniqueId, filterObject } from './../../../utils';\nimport { UploaderAbstract, INTELLIGENT_CHUNK_SIZE, MIN_CHUNK_SIZE, DEFAULT_STORE_LOCATION } from './abstract';\nimport { FilestackError, FilestackErrorType } from './../../../../filestack_error';\nvar debug = Debug('fs:upload:s3');\nvar COMPLETE_TIMEOUT = 1000 * 1;\n\nvar S3Uploader =\n/** @class */\nfunction (_super) {\n  tslib_1.__extends(S3Uploader, _super);\n\n  function S3Uploader(storeOptions, concurrency) {\n    var _this = _super.call(this, storeOptions, concurrency) || this;\n\n    _this.payloads = {};\n    _this.partsQueue = new PQueue({\n      autoStart: false,\n      concurrency: _this.concurrency\n    }); // setup cancel token\n\n    var CancelToken = request.CancelToken;\n    _this.cancelToken = CancelToken.source();\n    return _this;\n  }\n  /**\n   * Pause upload queue\n   *\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.pause = function () {\n    this.partsQueue.pause();\n  };\n  /**\n   * resume upload queue if its paused\n   *\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.resume = function () {\n    /* istanbul ignore next */\n    if (this.partsQueue.isPaused) {\n      this.partsQueue.start();\n    }\n  };\n  /**\n   * Aborts queue (all pending requests with will be aborted)\n   *\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.abort = function (msg) {\n    this.cancelToken.cancel(msg || 'Aborted by user');\n    this.partsQueue.clear();\n  };\n  /**\n   * Execute all queued files\n   *\n   * @returns {Promise<any>}\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.execute = function () {\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\n      var tasks;\n\n      var _this = this;\n\n      return tslib_1.__generator(this, function (_a) {\n        tasks = Object.keys(this.payloads).map(function (id) {\n          return new Promise(function (resolve) {\n            return tslib_1.__awaiter(_this, void 0, void 0, function () {\n              var e_1, file;\n              return tslib_1.__generator(this, function (_a) {\n                switch (_a.label) {\n                  case 0:\n                    _a.trys.push([0, 5,, 6]);\n\n                    return [4\n                    /*yield*/\n                    , this.startRequest(id)];\n\n                  case 1:\n                    _a.sent();\n\n                    return [4\n                    /*yield*/\n                    , this.prepareParts(id)];\n\n                  case 2:\n                    _a.sent();\n\n                    return [4\n                    /*yield*/\n                    , this.startPartsQueue(id)];\n\n                  case 3:\n                    _a.sent();\n\n                    return [4\n                    /*yield*/\n                    , this.completeRequest(id)];\n\n                  case 4:\n                    _a.sent();\n\n                    return [3\n                    /*break*/\n                    , 6];\n\n                  case 5:\n                    e_1 = _a.sent();\n                    /* istanbul ignore next */\n\n                    this.emit('error', e_1);\n                    debug(\"[\" + id + \"] File upload failed. %O, \\nDetails: %O \", e_1.message, e_1.details);\n                    return [3\n                    /*break*/\n                    , 6];\n\n                  case 6:\n                    file = this.getPayloadById(id).file; // release file buffer\n\n                    file.release(); // cleanup payloads\n\n                    delete this.payloads[id];\n                    resolve(file);\n                    return [2\n                    /*return*/\n                    ];\n                }\n              });\n            });\n          });\n        });\n        return [2\n        /*return*/\n        , Promise.all(tasks).then(function (res) {\n          // prevent cancel token memory leak\n          try {\n            _this.cancelToken.cancel();\n          } catch (e) {\n            /* istanbul ignore next */\n            debug(\"Cannot cleanup cancel token %O\", e.message);\n          }\n\n          return res;\n        })];\n      });\n    });\n  };\n  /**\n   * Add file to upload queue\n   *\n   * @param {File} file\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.addFile = function (file) {\n    debug('Add file to queue: \\n %o', file);\n    var id = uniqueId(15) + \"_\" + uniqueTime();\n    file.status = \"Initialized\"\n    /* INIT */\n    ; // split file into parts and set it as waiting\n\n    this.payloads[id] = {\n      file: file,\n      parts: []\n    };\n    return id;\n  };\n  /**\n   * Returns host for upload (region based)\n   *\n   * @private\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.getUploadUrl = function (id) {\n    var location_url = this.getDefaultFields(id, ['location_url']).location_url;\n    return location_url.indexOf('http') === 0 ? location_url : \"https://\" + location_url;\n  };\n  /**\n   * Returns formatted store options\n   *\n   * @private\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.getStoreOptions = function (id) {\n    var options = tslib_1.__assign({\n      location: DEFAULT_STORE_LOCATION\n    }, this.storeOptions);\n\n    if (this.storeOptions.disableStorageKey) {\n      var payload = this.getPayloadById(id);\n\n      if (options.path && options.path.substr(-1) !== '/') {\n        options.path = options.path + \"/\";\n      }\n\n      options.path = \"\" + (options.path ? options.path : '/') + payload.file.name;\n      delete options.disableStorageKey;\n    }\n\n    return options;\n  };\n  /**\n   * Returns all default fields for filestack requests\n   *\n   * @private\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.getDefaultFields = function (id, requiredFields, fiiFallback) {\n    if (fiiFallback === void 0) {\n      fiiFallback = false;\n    }\n\n    var payload = this.getPayloadById(id);\n\n    var fields = tslib_1.__assign({}, this.security, {\n      apikey: this.apikey,\n      uri: payload.uri,\n      location_url: payload.location_url,\n      upload_id: payload.upload_id,\n      region: payload.region\n    });\n\n    if (this.uploadMode === \"intelligent\"\n    /* INTELLIGENT */\n    || this.uploadMode === \"fallback\"\n    /* FALLBACK */\n    && fiiFallback) {\n      fields['fii'] = true;\n    }\n\n    return tslib_1.__assign({}, filterObject(fields, requiredFields), {\n      store: this.getStoreOptions(id)\n    });\n  };\n  /**\n   * Returns default headers needed for filestack request\n   *\n   * @private\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.getDefaultHeaders = function (id) {\n    var headers = {};\n    var file = this.getPayloadById(id);\n\n    if (file.location_region) {\n      headers['Filestack-Upload-Region'] = file.location_region;\n    }\n\n    return headers;\n  };\n\n  S3Uploader.prototype.getPayloadById = function (id) {\n    return this.payloads[id];\n  };\n  /**\n   * Split file onto parts for uploading with multipart mechanism and setup start\n   *\n   * @private\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.prepareParts = function (id) {\n    var file = this.getPayloadById(id).file; // for intelligent or fallback mode we cant overwrite part size - requires 8MB\n\n    if ([\"intelligent\"\n    /* INTELLIGENT */\n    , \"fallback\"\n    /* FALLBACK */\n    ].indexOf(this.uploadMode) > -1) {\n      this.partSize = INTELLIGENT_CHUNK_SIZE;\n    }\n\n    var partsCount = file.getPartsCount(this.partSize);\n    var parts = [];\n\n    for (var i = 0; i < partsCount; i++) {\n      parts[i] = tslib_1.__assign({}, file.getPartMetadata(i, this.partSize), {\n        offset: 0\n      });\n    } // split file into parts and set it as waiting\n\n\n    this.payloads[id].parts = parts;\n    return Promise.resolve();\n  };\n  /**\n   * Make start request for getting needed upload fields\n   *\n   * @private\n   * @returns {Promise<any>}\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.startRequest = function (id) {\n    var _this = this;\n\n    var payload = this.getPayloadById(id);\n    debug(\"[\" + id + \"] Make start request\");\n    return postWithRetry(this.getUrl() + \"/multipart/start\", tslib_1.__assign({\n      filename: payload.file.name,\n      mimetype: payload.file.type,\n      size: payload.file.size\n    }, this.getDefaultFields(id, ['apikey', 'policy', 'signature', 'fii'], true)), {\n      timeout: this.timeout,\n      cancelToken: this.cancelToken.token,\n      headers: this.getDefaultHeaders(id)\n    }, this.retryConfig).then(function (_a) {\n      var data = _a.data;\n\n      if (!data || !data.location_url || !data.region || !data.upload_id || !data.uri) {\n        debug(\"[\" + id + \"] Incorrect start response: \\n%O\\n\", data);\n\n        _this.setPayloadStatus(id, \"Failed\"\n        /* FAILED */\n        );\n\n        return Promise.reject(new FilestackError('Incorrect start response', data, FilestackErrorType.REQUEST));\n      }\n\n      debug(\"[\" + id + \"] Assign payload data: \\n%O\\n\", data);\n\n      _this.updatePayload(id, data); // ii is not enabled in backend switch back to default upload mode\n\n\n      if ([\"intelligent\"\n      /* INTELLIGENT */\n      , \"fallback\"\n      /* FALLBACK */\n      ].indexOf(_this.uploadMode) > -1 && (!data.upload_type || data.upload_type !== 'intelligent_ingestion')) {\n        debug(\"[\" + id + \"] Intelligent Ingestion is not enabled on account, switch back to regular upload and lock mode change\");\n\n        _this.setUploadMode(\"default\"\n        /* DEFAULT */\n        , true);\n      }\n\n      return data;\n    }).catch(function (err) {\n      debug(\"[\" + id + \"] Start request error %O\", err);\n\n      _this.setPayloadStatus(id, \"Failed\"\n      /* FAILED */\n      );\n\n      return Promise.reject(new FilestackError('Cannot upload file. Start request failed', {\n        code: err.response.status,\n        data: err.response.data,\n        headers: err.response.headers\n      }, FilestackErrorType.REQUEST));\n    });\n  };\n  /**\n   * Enqueue file parts to upload\n   *\n   * @private\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.startPartsQueue = function (id) {\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\n      var payload, parts, waitingLength;\n\n      var _this = this;\n\n      return tslib_1.__generator(this, function (_a) {\n        payload = this.getPayloadById(id);\n        parts = payload.parts;\n        waitingLength = parts.length;\n        debug(\"[\" + id + \"] Create uploading queue from file. parts count - %d\", waitingLength);\n        return [2\n        /*return*/\n        , new Promise(function (resolve, reject) {\n          return tslib_1.__awaiter(_this, void 0, void 0, function () {\n            var _a;\n\n            var _this = this;\n\n            return tslib_1.__generator(this, function (_b) {\n              switch (_b.label) {\n                case 0:\n                  parts.forEach(function (part) {\n                    return _this.partsQueue.add(function () {\n                      return _this.startPart(id, part.partNumber);\n                    }).catch(function (e) {\n                      _this.setPayloadStatus(id, \"Failed\"\n                      /* FAILED */\n                      );\n\n                      debug(\"[\" + id + \"] Failed to upload part %s\", e.message);\n\n                      _this.partsQueue.pause();\n\n                      _this.partsQueue.clear();\n\n                      return reject(e);\n                    });\n                  });\n                  debug(\"[\" + id + \"] All tasks for %s enqueued. Start processing main upload queue\", id);\n                  this.partsQueue.start();\n                  _a = resolve;\n                  return [4\n                  /*yield*/\n                  , this.partsQueue.onIdle()];\n\n                case 1:\n                  _a.apply(void 0, [_b.sent()]);\n\n                  return [2\n                  /*return*/\n                  ];\n              }\n            });\n          });\n        })];\n      });\n    });\n  };\n  /**\n   * Decide if upload should be made using ii or regular upload\n   * It allows change upload mode during upload queue\n   *\n   * @private\n   * @param {number} partNumber\n   * @returns {Promise<any>}\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.startPart = function (id, partNumber) {\n    debug(\"[\" + id + \"] Start processing part \" + partNumber + \" with mode \" + this.uploadMode);\n    var payload = this.getPayloadById(id);\n    payload.file.status = \"Progress\"\n    /* PROGRESS */\n    ;\n    return (this.uploadMode !== \"intelligent\"\n    /* INTELLIGENT */\n    ? this.uploadRegular : this.uploadIntelligent).apply(this, [id, partNumber]);\n  };\n  /**\n   * Returns part data needed for upload\n   *\n   * @private\n   * @param {string} id - id of a currently uploading file\n   * @param {FilePart} part\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.getS3PartMetadata = function (id, part, offset) {\n    var _this = this;\n\n    var url = this.getUploadUrl(id);\n    debug(\"[\" + id + \"] Get data for part \" + part.partNumber + \", url \" + url + \", Md5: \" + part.md5 + \", Size: \" + part.size);\n\n    var data = tslib_1.__assign({}, this.getDefaultFields(id, ['apikey', 'uri', 'region', 'signature', 'policy', 'upload_id', 'fii']), {\n      // method specific keys\n      part: part.partNumber + 1,\n      size: part.size,\n      offset: offset\n    });\n\n    if (this.integrityCheck && part.md5) {\n      data.md5 = part.md5;\n    }\n\n    return postWithRetry(url + \"/multipart/upload\", data, {\n      headers: this.getDefaultHeaders(id),\n      cancelToken: this.cancelToken.token,\n      timeout: this.timeout\n    }, this.retryConfig).catch(function (err) {\n      _this.setPayloadStatus(id, \"Failed\"\n      /* FAILED */\n      );\n\n      return Promise.reject(new FilestackError('Cannot get part metadata', {\n        code: err.response.status,\n        data: err.response.data,\n        headers: err.response.headers\n      }, FilestackErrorType.REQUEST));\n    });\n  };\n  /**\n   * Regular multipart request to amazon\n   *\n   * @private\n   * @param {number} partNumber\n   * @returns {Promise<any>}\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.uploadRegular = function (id, partNumber) {\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\n      var payload, partMetadata, part, _a, data, headers;\n\n      var _this = this;\n\n      return tslib_1.__generator(this, function (_b) {\n        switch (_b.label) {\n          case 0:\n            payload = this.getPayloadById(id);\n            partMetadata = payload.parts[partNumber];\n            return [4\n            /*yield*/\n            , payload.file.getPartByMetadata(partMetadata, this.integrityCheck)];\n\n          case 1:\n            part = _b.sent();\n            return [4\n            /*yield*/\n            , this.getS3PartMetadata(id, part)];\n\n          case 2:\n            _a = _b.sent(), data = _a.data, headers = _a.headers;\n            debug(\"[\" + id + \"] Received part \" + partNumber + \" info body: \\n%O\\n headers: \\n%O\\n\", data, headers); // retry only in regular upload mode\n\n            if (this.retryConfig && this.uploadMode !== \"fallback\"\n            /* FALLBACK */\n            ) {\n                useRetryPolicy(request, this.retryConfig);\n              }\n\n            return [2\n            /*return*/\n            , request.put(data.url, part.buffer, {\n              cancelToken: this.cancelToken.token,\n              timeout: this.timeout,\n              headers: data.headers,\n              // for now we cant test progress callback from upload\n\n              /* istanbul ignore next */\n              onUploadProgress: function (pr) {\n                return _this.onProgressUpdate(id, partNumber, pr.loaded);\n              }\n            }).then(function (res) {\n              if (res.headers.etag) {\n                _this.setPartETag(id, partNumber, res.headers.etag);\n              } else {\n                throw new FilestackError('Cannot upload file, check S3 bucket settings', 'Etag header is not exposed in CORS settings', FilestackErrorType.REQUEST);\n              }\n\n              debug(\"[\" + id + \"] S3 Upload response headers for \" + partNumber + \": \\n%O\\n\", res.headers);\n\n              _this.onProgressUpdate(id, partNumber, part.size);\n\n              return res;\n            }).catch(function (err) {\n              if (err instanceof FilestackError) {\n                return Promise.reject(err);\n              } // reset upload progress on failed part\n\n\n              _this.onProgressUpdate(id, partNumber, 0); // if fallback, set upload mode to intelligent and restart current part\n\n\n              if (_this.uploadMode === \"fallback\"\n              /* FALLBACK */\n              && !_this.isModeLocked || _this.uploadMode === \"intelligent\"\n              /* INTELLIGENT */\n              ) {\n                  debug(\"[\" + id + \"] Regular upload failed. Switching to intelligent ingestion mode\");\n\n                  _this.setUploadMode(\"intelligent\"\n                  /* INTELLIGENT */\n                  ); // restart part\n\n\n                  return _this.startPart(id, partNumber);\n                }\n\n              return Promise.reject(new FilestackError('Cannot upload file part', {\n                code: err.response.status,\n                data: err.response.data,\n                headers: err.response.headers\n              }, FilestackErrorType.REQUEST));\n            })];\n        }\n      });\n    });\n  };\n  /**\n   * Upload file using intelligent mechanism\n   *\n   * @private\n   * @param {string} id\n   * @param {number} partNumber\n   * @returns {Promise<any>}\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.uploadIntelligent = function (id, partNumber) {\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\n      var _this = this;\n\n      return tslib_1.__generator(this, function (_a) {\n        return [2\n        /*return*/\n        , this.uploadNextChunk(id, partNumber).then(function () {\n          return _this.commitPart(id, partNumber);\n        })];\n      });\n    });\n  };\n  /**\n   * Recursively upload file in chunk mode (intelligent ingession)\n   *\n   * @private\n   * @param {string} id\n   * @param {number} partNumber\n   * @param {number} chunkSize\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.uploadNextChunk = function (id, partNumber, chunkSize) {\n    if (chunkSize === void 0) {\n      chunkSize = this.intelligentChunkSize;\n    }\n\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\n      var payload, part, chunk, data;\n\n      var _this = this;\n\n      return tslib_1.__generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            payload = this.getPayloadById(id);\n            part = payload.parts[partNumber];\n            chunkSize = Math.min(chunkSize, part.size - part.offset);\n            return [4\n            /*yield*/\n            , payload.file.getChunkByMetadata(part, part.offset, chunkSize, this.integrityCheck)];\n\n          case 1:\n            chunk = _a.sent();\n            debug(\"[\" + id + \"] PartNum: \" + partNumber + \", PartSize: \" + part.size + \", StartByte: \" + part.startByte + \", Offset: \" + part.offset + \", ChunkSize: \" + chunk.size + \",\\n       Left: \" + (part.size - part.offset - chunk.size));\n            return [4\n            /*yield*/\n            , this.getS3PartMetadata(id, chunk, part.offset).catch(function (err) {\n              debug(\"[\" + id + \"] Getting chunk data for ii failed %O, Chunk size: \" + chunkSize + \", offset \" + part.offset + \", part \" + partNumber, err);\n              return Promise.reject(err);\n            })];\n\n          case 2:\n            data = _a.sent().data;\n            return [2\n            /*return*/\n            , request.put(data.url, chunk.buffer, {\n              cancelToken: this.cancelToken.token,\n              timeout: this.timeout,\n              headers: data.headers,\n              // for now we cant test progress callback from upload\n\n              /* istanbul ignore next */\n              onUploadProgress: function (pr) {\n                return _this.onProgressUpdate(id, partNumber, part.offset + pr.loaded);\n              }\n            }).then(function (res) {\n              _this.onProgressUpdate(id, partNumber, part.offset + chunk.size);\n\n              var newOffset = Math.min(part.offset + chunkSize, part.size);\n              debug(\"[\" + id + \"] S3 Chunk uploaded! offset: \" + part.offset + \", part \" + partNumber + \"! response headers for \" + partNumber + \": \\n%O\\n\", res.headers);\n\n              _this.setPartData(id, partNumber, 'offset', newOffset); // if all chunks was uploaded then return resolve\n\n\n              if (newOffset === part.size) {\n                return Promise.resolve(res);\n              }\n\n              part = null;\n              chunk = null;\n              return _this.uploadNextChunk(id, partNumber, chunkSize);\n            }).catch(function (err) {\n              // reset progress on failed upload\n              _this.onProgressUpdate(id, partNumber, part.offset);\n\n              var nextChunkSize = chunkSize / 2;\n\n              if (nextChunkSize < MIN_CHUNK_SIZE) {\n                debug(\"[\" + id + \"] Minimal chunk size limit. Upload file failed!\");\n                return Promise.reject(new FilestackError('Min chunk size reached', err.data, FilestackErrorType.REQUEST));\n              }\n\n              if (shouldRetry(err)) {\n                debug(\"[\" + id + \"] Request network error. Retry with new chunk size: \" + nextChunkSize);\n                return _this.uploadNextChunk(id, partNumber, nextChunkSize);\n              }\n\n              part = null;\n              chunk = null;\n              return Promise.reject(new FilestackError('Cannot upload file part (FII)', {\n                code: err.response.status,\n                data: err.response.data,\n                headers: err.response.headers\n              }, FilestackErrorType.REQUEST));\n            })];\n        }\n      });\n    });\n  };\n  /**\n   * Commit after upload all chunks of the part in ii mode\n   *\n   * @private\n   * @param {string} id\n   * @param {FilePart} part\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.commitPart = function (id, partNumber) {\n    var payload = this.getPayloadById(id);\n    var part = payload.parts[partNumber];\n    return postWithRetry(this.getUploadUrl(id) + \"/multipart/commit\", tslib_1.__assign({}, this.getDefaultFields(id, ['apikey', 'region', 'upload_id', 'policy', 'signature', 'uri']), {\n      size: payload.file.size,\n      part: part.partNumber + 1\n    }), {\n      cancelToken: this.cancelToken.token,\n      timeout: this.timeout,\n      headers: this.getDefaultHeaders(id)\n    }, this.retryConfig).then(function (res) {\n      debug(\"[\" + id + \"] Commit Part number \" + part.partNumber + \". Response: %O\", res.data);\n      return res;\n    }).catch(function (err) {\n      return Promise.reject(new FilestackError('Cannot commit file part metadata', {\n        code: err.response.status,\n        data: err.response.data,\n        headers: err.response.headers\n      }, FilestackErrorType.REQUEST));\n    });\n  };\n  /**\n   * Complete request to merge all parts and get file handle etc\n   *\n   * @private\n   * @returns\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.completeRequest = function (id) {\n    var _this = this;\n\n    var payload = this.getPayloadById(id);\n    var parts = [];\n    debug(\"[\" + id + \"] Run complete request\");\n    var partsHandle = payload.parts;\n    var partLen = partsHandle.length;\n\n    for (var i = 0; i < partLen; i++) {\n      if (partsHandle[i].etag) {\n        parts.push({\n          part_number: i + 1,\n          etag: partsHandle[i].etag\n        });\n      }\n    }\n\n    debug(\"[\" + id + \"] Etags %O\", parts);\n    return postWithRetry(this.getUrl() + \"/multipart/complete\", tslib_1.__assign({}, this.getDefaultFields(id, ['apikey', 'policy', 'signature', 'uri', 'region', 'upload_id', 'fii'], true), {\n      // method specific keys\n      filename: payload.file.name,\n      mimetype: payload.file.type,\n      size: payload.file.size,\n      parts: parts.length ? parts : undefined\n    }), {\n      timeout: this.timeout,\n      cancelToken: this.cancelToken.token,\n      headers: this.getDefaultHeaders(id)\n    }, this.retryConfig).then(function (res) {\n      // if parts hasnt been merged, retry complete request again\n      if (res.status === 202) {\n        return new Promise(function (resolve, reject) {\n          setTimeout(function () {\n            return _this.completeRequest(id).then(resolve).catch(reject);\n          }, COMPLETE_TIMEOUT);\n        });\n      } // update file object\n\n\n      var file = _this.getPayloadById(id).file;\n\n      file.handle = res.data.handle;\n      file.url = res.data.url;\n      file.container = res.data.container;\n      file.key = res.data.key;\n      file.workflows = res.data.workflows;\n      file.status = res.data.status;\n      return file;\n    }).catch(function (err) {\n      _this.setPayloadStatus(id, \"Failed\"\n      /* FAILED */\n      );\n\n      return Promise.reject(new FilestackError('Cannot complete file', {\n        code: err.response.status,\n        data: err.response.data,\n        headers: err.response.headers\n      }, FilestackErrorType.REQUEST));\n    });\n  };\n  /**\n   * UUpgrade upload progress and run progress event\n   *\n   * @private\n   * @param {string} id\n   * @param {number} partNumber\n   * @param {number} loaded\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.onProgressUpdate = function (id, partNumber, loaded) {\n    this.setPartData(id, partNumber, 'progress', loaded);\n    this.emitProgress();\n  };\n  /**\n   * Emits normalized progress event\n   *\n   * @private\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.emitProgress = function () {\n    var totalSize = 0;\n    var totalBytes = 0;\n    var filesProgress = {};\n\n    for (var i in this.payloads) {\n      var payload = this.payloads[i]; // omit all failed files in progress event\n      // this shouldn't happend because of promises rejection in execute. Left to be sure\n\n      /* istanbul ignore next */\n\n      if (payload.file.status === \"Failed\"\n      /* FAILED */\n      ) {\n          continue;\n        }\n\n      var partsProgress = payload.parts.map(function (p) {\n        return p.progress || 0;\n      });\n      var totalParts = partsProgress.reduce(function (a, b) {\n        return a + b;\n      });\n      totalBytes = totalBytes + totalParts;\n      filesProgress[i] = {\n        totalBytes: totalParts || 0,\n        totalPercent: Math.round(totalParts * 100 / payload.file.size) || 0\n      };\n      totalSize = totalSize + payload.file.size;\n    }\n\n    var res = {\n      totalBytes: totalBytes || 0,\n      totalPercent: Math.round(totalBytes * 100 / totalSize) || 0,\n      files: filesProgress\n    };\n    debug(\"Upload progress %O\", res);\n    this.emit('progress', res);\n  };\n  /**\n   * Apply provided data to given payload\n   *\n   * @private\n   * @param {string} id\n   * @param {*} data\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.updatePayload = function (id, data) {\n    this.payloads[id] = tslib_1.__assign({}, this.payloads[id], data);\n  };\n  /**\n   * Sets etag for part\n   *\n   * @private\n   * @param {number} partNumber\n   * @param {string} etag\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.setPartETag = function (id, partNumber, etag) {\n    debug(\"[\" + id + \"] Set \" + etag + \" etag for part \" + partNumber);\n    this.getPayloadById(id).parts[partNumber].etag = etag;\n  };\n  /**\n   * Sets part value for a key\n   *\n   * @private\n   * @param {number} partNumber\n   * @param {string} etag\n   * @memberof S3Uploader\n   */\n\n\n  S3Uploader.prototype.setPartData = function (id, partNumber, key, value) {\n    debug(\"[\" + id + \"] Set \" + key + \" = \" + value + \" for part \" + partNumber);\n    var payload = this.getPayloadById(id);\n    /* istanbul ignore next */\n\n    if (!payload) {\n      debug(\"[\" + id + \"] Cannot set \" + key + \" = \" + value + \" for part \" + partNumber);\n      return;\n    }\n\n    payload.parts[partNumber][key] = value;\n  };\n  /**\n   * Set payload file state\n   *\n   * @param id\n   * @param status\n   */\n\n\n  S3Uploader.prototype.setPayloadStatus = function (id, status) {\n    debug(\"[\" + id + \"] Set payload status to \" + status);\n    this.payloads[id].file.status = status;\n  };\n\n  return S3Uploader;\n}(UploaderAbstract);\n\nexport { S3Uploader };","map":null,"metadata":{},"sourceType":"module"}